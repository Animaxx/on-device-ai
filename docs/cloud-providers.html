<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cloud Providers - On Device AI Docs</title>
    <meta name="description"
        content="Optionally connect to Nvidia, OpenAI, Anthropic, Google Gemini, Groq, OpenRouter, LM Studio, or Ollama in On Device AI.">
    <link rel="icon" type="image/png" href="../images/favicon.png">
    <link rel="canonical" href="https://OnDevice-ai.app/docs/cloud-providers.html">
    <link rel="stylesheet" href="../css/styles.css">
    <link rel="stylesheet" href="../css/docs.css">
</head>

<body>
    <header class="site-header scrolled">
        <div class="container header-inner">
            <a href="../index.html" class="logo"><img src="../images/icon.png" alt="On Device AI"><span>On Device
                    AI</span></a>
            <ul class="nav-links">
                <li><a href="../index.html">Home</a></li>
                <li><a href="./" class="active">Docs</a></li>
                <li><button class="theme-toggle" aria-label="Toggle theme"><svg class="icon-moon" viewBox="0 0 24 24"
                            fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z" />
                        </svg><svg class="icon-sun" viewBox="0 0 24 24" fill="none" stroke="currentColor"
                            stroke-width="2">
                            <circle cx="12" cy="12" r="5" />
                            <line x1="12" y1="1" x2="12" y2="3" />
                            <line x1="12" y1="21" x2="12" y2="23" />
                            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64" />
                            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78" />
                            <line x1="1" y1="12" x2="3" y2="12" />
                            <line x1="21" y1="12" x2="23" y2="12" />
                            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36" />
                            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22" />
                        </svg></button></li>
                <li><a href="https://apps.apple.com/us/app/on-device-ai/id6497060890" class="nav-cta">Download</a></li>
            </ul>
            <button class="mobile-menu-btn" aria-label="Menu"><span></span><span></span><span></span></button>
        </div>
    </header>
    <div class="docs-layout">
        <aside class="docs-sidebar">
            <div class="docs-search">
                <svg class="docs-search-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <circle cx="11" cy="11" r="8" />
                    <line x1="21" y1="21" x2="16.65" y2="16.65" />
                </svg>
                <input type="text" class="docs-search-input" placeholder="Search docs..."
                    aria-label="Search documentation">
                <div class="docs-search-results"></div>
            </div>
            <div class="sidebar-section">
                <div class="sidebar-section-title">Getting Started</div>
                <ul class="sidebar-nav">
                    <li><a href="index.html">Overview</a></li>
                    <li><a href="getting-started.html">Quick Start</a></li>
                </ul>
            </div>
            <div class="sidebar-section">
                <div class="sidebar-section-title">Core Guides</div>
                <ul class="sidebar-nav">
                    <li><a href="ai-chat.html">AI Chat</a></li>
                    <li><a href="knowledge-libraries.html">Knowledge Libraries</a></li>
                    <li><a href="voice-notes.html">Voice Notes</a></li>
                    <li><a href="text-to-speech.html">Text-to-Speech</a></li>
                    <li><a href="web-search.html">Web Search</a></li>
                    <li><a href="vision-models.html">Vision Models</a></li>
                    <li><a href="chat-flows.html">Chat Flows</a></li>
                    <li><a href="roles-personas.html">Roles &amp; Personas</a></li>
                    <li><a href="cloud-providers.html" class="active">Cloud Providers</a></li>
                </ul>
            </div>
        </aside>
        <main class="docs-content">
            <h1>Cloud Providers</h1>
            <p>While On Device AI is designed for 100% offline operation, you can optionally connect to cloud AI
                providers when you need access to larger models or additional capabilities. Cloud is always
                <strong>opt-in</strong> and off by default.</p>

            <div class="toc">
                <div class="toc-title">On this page</div>
                <ul>
                    <li><a href="#supported">Supported Providers</a></li>
                    <li><a href="#setup">Setting Up a Provider</a></li>
                    <li><a href="#switching">Switching Between Local &amp; Cloud</a></li>
                    <li><a href="#privacy">Privacy Considerations</a></li>
                    <li><a href="#local-servers">Local Servers (Ollama &amp; LM Studio)</a></li>
                </ul>
            </div>

            <h2 id="supported">Supported Providers</h2>
            <p>On Device AI supports the following cloud and local server providers:</p>
            <ul>
                <li><strong>OpenAI:</strong> GPT-4o, GPT-4 Turbo, GPT-3.5 Turbo, and more</li>
                <li><strong>Anthropic:</strong> Claude 3 Opus, Sonnet, Haiku, and Claude 4 models</li>
                <li><strong>Google Gemini:</strong> Gemini Pro, Gemini Flash, and other models</li>
                <li><strong>Groq:</strong> Ultra-fast inference for Llama, Mixtral, and Gemma models</li>
                <li><strong>OpenRouter:</strong> Access to hundreds of models through a single API</li>
                <li><strong>Nvidia:</strong> Access Nvidia's NIM microservices and high-performance models</li>
                <li><strong>LM Studio:</strong> Connect to locally-hosted models running on your Mac or PC</li>
                <li><strong>Ollama:</strong> Connect to locally-hosted Ollama server</li>
            </ul>

            <h2 id="setup">Setting Up a Provider</h2>
            <ol class="steps">
                <li><strong>Open Settings ‚Üí Cloud Providers</strong>
                    <p>Navigate to the Cloud Providers section in app settings.</p>
                </li>
                <li><strong>Select a provider</strong>
                    <p>Choose the provider you want to connect to.</p>
                </li>
                <li><strong>Enter your API key</strong>
                    <p>Paste your API key from the provider's dashboard. The key is stored securely in your device's
                        Keychain ‚Äî never in plain text.</p>
                </li>
                <li><strong>Select a model</strong>
                    <p>Browse available models from the provider and select the one you want to use.</p>
                </li>
            </ol>
            <div class="callout callout-warning">
                <div class="callout-title">‚ö†Ô∏è Important</div>
                <p>When using cloud providers, your conversation data is transmitted to the provider's servers. The app
                    does not control how providers handle your data. Review each provider's privacy policy before use.
                </p>
            </div>

            <h2 id="switching">Switching Between Local &amp; Cloud</h2>
            <p>You can switch between local and cloud models at any time, even within the same conversation:</p>
            <ul>
                <li>Open the model picker</li>
                <li>Cloud models appear alongside local models, clearly labeled with the provider name</li>
                <li>Select any model to switch ‚Äî the conversation context is maintained</li>
            </ul>
            <div class="callout callout-info">
                <div class="callout-title">‚ÑπÔ∏è Note</div>
                <p>When you switch from a local model to a cloud model mid-conversation, your conversation history is
                    sent to the cloud provider. Consider starting a new conversation if you have sensitive content.</p>
            </div>

            <h2 id="privacy">Privacy Considerations</h2>
            <p>On Device AI is designed with privacy first:</p>
            <ul>
                <li><strong>Cloud is always opt-in:</strong> No data is ever sent to any server unless you explicitly
                    configure and select a cloud provider</li>
                <li><strong>API keys stored in Keychain:</strong> Your credentials are stored using Apple's secure
                    Keychain, not in UserDefaults or plain text</li>
                <li><strong>Direct connection:</strong> Data goes directly from your device to the provider ‚Äî we don't
                    proxy or store anything</li>
                <li><strong>Clear indicators:</strong> The UI clearly shows when you're using a cloud model vs. a local
                    one</li>
            </ul>

            <h2 id="local-servers">Local Servers (Ollama &amp; LM Studio)</h2>
            <p>Ollama and LM Studio are special cases ‚Äî they run AI models on your own hardware (Mac, PC, or server)
                rather than in the cloud. This gives you the power of larger models while maintaining privacy:</p>
            <ul>
                <li><strong>Ollama:</strong> Set the server URL (default: <code>http://localhost:11434</code>) in
                    Settings</li>
                <li><strong>LM Studio:</strong> Set the server URL (default: <code>http://localhost:1234</code>) in
                    Settings</li>
            </ul>
            <p>Your data stays on your local network when using these providers. This is a great option for running
                larger models on a powerful Mac while chatting from your iPhone.</p>
            <div class="callout callout-tip">
                <div class="callout-title">üí° Tip</div>
                <p>On Device AI can also serve as a remote inference server itself (macOS). Connect your iPhone to your
                    Mac running On Device AI for the best of both worlds.</p>
            </div>

            <div class="docs-nav-footer">
                <a href="roles-personas.html" class="docs-nav-link prev"><span class="nav-label">‚Üê Previous</span><span
                        class="nav-title">Roles &amp; Personas</span></a>
                <a href="index.html" class="docs-nav-link next"><span class="nav-label">Back to ‚Üí</span><span
                        class="nav-title">Documentation Home</span></a>
            </div>
        </main>
    </div>
    <button class="docs-sidebar-toggle" aria-label="Toggle sidebar"><svg viewBox="0 0 24 24" fill="none"
            stroke="currentColor" stroke-width="2">
            <line x1="3" y1="12" x2="21" y2="12" />
            <line x1="3" y1="6" x2="21" y2="6" />
            <line x1="3" y1="18" x2="21" y2="18" />
        </svg></button>
    <script src="https://cdn.jsdelivr.net/npm/fuse.js@7.0.0"></script>
    <script src="../js/search-index.js"></script>
    <script src="../js/main.js"></script>
    <script src="../js/docs.js"></script>
    <script src="../js/search.js"></script>
</body>

</html>